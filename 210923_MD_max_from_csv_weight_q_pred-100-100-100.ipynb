{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from logp.zq.io.smi2feat import load_feat_from_csv\n",
    "from logp.zq.io.load_dataframe import load_pd\n",
    "from logp.zq.model.model import potential_model\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from logp.zq.io.base import sparse_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filename = 'logp/DATASETS/sf_ave_PhysProp_MD_weights_charge.csv'\n",
    "#dataset = pd.read_csv(filename)\n",
    "#dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results = load_pd(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the predicting data in martel\n",
    "filename_martel = 'logp/DATASETS/Martel/MD_max/weight_q/sf_max_Martel_MD_weights_charge.csv'\n",
    "dataset_martel = pd.read_csv(filename_martel)\n",
    "dataset_martel.shape\n",
    "results_martel = load_pd(filename_martel)\n",
    "dataset_martel = lambda: load_feat_from_csv(results_martel,24,split={'train':10,'test':0},shuffle=False)\n",
    "martel_train = lambda: dataset_martel()['train'].apply(sparse_batch(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the predicting data in star\n",
    "filename_star = 'logp/DATASETS/star_nonstar/MD_max/weight_q/sf_max_star_MD_weights_charge.csv'\n",
    "dataset_star = pd.read_csv(filename_star)\n",
    "dataset_star.shape\n",
    "results_star = load_pd(filename_star)\n",
    "\n",
    "dataset_star = lambda: load_feat_from_csv(results_star,24,split={'train':10,'test':0},shuffle=False)\n",
    "star_train = lambda: dataset_star()['train'].apply(sparse_batch(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the predicting data in huusk\n",
    "filename_nonstar = 'logp/DATASETS/Huuskonen/MD_max/weight_q/sf_max_Huuskonen_MD_weights_charge.csv'\n",
    "dataset_nonstar = pd.read_csv(filename_nonstar)\n",
    "dataset_nonstar.shape\n",
    "results_nonstar = load_pd(filename_nonstar)\n",
    "\n",
    "dataset_nonstar = lambda: load_feat_from_csv(results_nonstar,24,split={'train':10,'test':0},shuffle=False)\n",
    "nonstar_train = lambda: dataset_nonstar()['train'].apply(sparse_batch(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /opt/anaconda2/envs/tf24/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/zhuqiang/LogP_prediction/logp_prediction/logp/zq/io/base.py:118: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/zhuqiang/LogP_prediction/logp_prediction/logp/zq/io/base.py:118: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt-183221\n",
      "WARNING:tensorflow:From /opt/anaconda2/envs/tf24/lib/python3.8/site-packages/tensorflow/python/training/saver.py:1076: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 183221...\n",
      "INFO:tensorflow:Saving checkpoints for 183221 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 183221...\n",
      "WARNING:tensorflow:From /opt/anaconda2/envs/tf24/lib/python3.8/site-packages/tensorflow/python/summary/summary_iterator.py:31: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 61877 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 183221\n",
      "INFO:tensorflow:loss = 2.1431522, step = 183221\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 183222...\n",
      "INFO:tensorflow:Saving checkpoints for 183222 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt.\n",
      "WARNING:tensorflow:From /opt/anaconda2/envs/tf24/lib/python3.8/site-packages/tensorflow/python/training/saver.py:968: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 183222...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:47:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt-183222\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.21485s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:47:07\n",
      "INFO:tensorflow:Saving dict for global step 183222: METRICS/E_LOSS = 3.0618546, METRICS/E_MAE = 1.4899683, METRICS/E_MSE = 3.0618546, METRICS/E_RMSE = 1.7498156, METRICS/TOT_LOSS = 3.061856, global_step = 183222, loss = 3.061856\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 183222: MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt-183222\n",
      "INFO:tensorflow:Loss for final step: 2.1431522.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt-183222\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt-183222\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_0/model.ckpt-183222\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt-125616\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 125616...\n",
      "INFO:tensorflow:Saving checkpoints for 125616 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 125616...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62502 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 125616\n",
      "INFO:tensorflow:loss = 1.8185235, step = 125616\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 125617...\n",
      "INFO:tensorflow:Saving checkpoints for 125617 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 125617...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:47:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt-125617\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19857s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:47:19\n",
      "INFO:tensorflow:Saving dict for global step 125617: METRICS/E_LOSS = 5.1240396, METRICS/E_MAE = 1.9376131, METRICS/E_MSE = 5.1240396, METRICS/E_RMSE = 2.2636342, METRICS/TOT_LOSS = 5.12404, global_step = 125617, loss = 5.12404\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 125617: MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt-125617\n",
      "INFO:tensorflow:Loss for final step: 1.8185235.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt-125617\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt-125617\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_2/model.ckpt-125617\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt-125501\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 125501...\n",
      "INFO:tensorflow:Saving checkpoints for 125501 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 125501...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62618 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 125501\n",
      "INFO:tensorflow:loss = 6.4343657, step = 125501\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 125502...\n",
      "INFO:tensorflow:Saving checkpoints for 125502 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 125502...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:47:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt-125502\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.21360s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:47:27\n",
      "INFO:tensorflow:Saving dict for global step 125502: METRICS/E_LOSS = 4.2874136, METRICS/E_MAE = 1.5668533, METRICS/E_MSE = 4.2874136, METRICS/E_RMSE = 2.070607, METRICS/TOT_LOSS = 4.287415, global_step = 125502, loss = 4.287415\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 125502: MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt-125502\n",
      "INFO:tensorflow:Loss for final step: 6.4343657.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt-125502\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt-125502\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_3/model.ckpt-125502\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt-187189\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187189...\n",
      "INFO:tensorflow:Saving checkpoints for 187189 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187189...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 61991 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 187189\n",
      "INFO:tensorflow:loss = 2.3954008, step = 187189\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187190...\n",
      "INFO:tensorflow:Saving checkpoints for 187190 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187190...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:47:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt-187190\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19408s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:47:36\n",
      "INFO:tensorflow:Saving dict for global step 187190: METRICS/E_LOSS = 2.6732512, METRICS/E_MAE = 1.4144758, METRICS/E_MSE = 2.6732512, METRICS/E_RMSE = 1.635008, METRICS/TOT_LOSS = 2.6732504, global_step = 187190, loss = 2.6732504\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187190: MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt-187190\n",
      "INFO:tensorflow:Loss for final step: 2.3954008.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt-187190\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt-187190\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_4/model.ckpt-187190\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt-188464\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188464...\n",
      "INFO:tensorflow:Saving checkpoints for 188464 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188464...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62671 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 188464\n",
      "INFO:tensorflow:loss = 15.190448, step = 188464\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188465...\n",
      "INFO:tensorflow:Saving checkpoints for 188465 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188465...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:47:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt-188465\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.20525s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:47:44\n",
      "INFO:tensorflow:Saving dict for global step 188465: METRICS/E_LOSS = 28.06095, METRICS/E_MAE = 4.201001, METRICS/E_MSE = 28.06095, METRICS/E_RMSE = 5.297259, METRICS/TOT_LOSS = 28.060942, global_step = 188465, loss = 28.060942\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 188465: MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt-188465\n",
      "INFO:tensorflow:Loss for final step: 15.190448.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt-188465\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt-188465\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_5/model.ckpt-188465\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt-188047\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188047...\n",
      "INFO:tensorflow:Saving checkpoints for 188047 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188047...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62451 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 188047\n",
      "INFO:tensorflow:loss = 4.1125727, step = 188047\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188048...\n",
      "INFO:tensorflow:Saving checkpoints for 188048 into MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188048...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:47:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt-188048\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19636s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:47:56\n",
      "INFO:tensorflow:Saving dict for global step 188048: METRICS/E_LOSS = 6.607236, METRICS/E_MAE = 2.2987068, METRICS/E_MSE = 6.607236, METRICS/E_RMSE = 2.5704544, METRICS/TOT_LOSS = 6.6072326, global_step = 188048, loss = 6.6072326\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 188048: MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt-188048\n",
      "INFO:tensorflow:Loss for final step: 4.1125727.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt-188048\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt-188048\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_7/model.ckpt-188048\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.01/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_0/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_0/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_0/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_2/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_2/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_2/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_3/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_3/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_3/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_4/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_4/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_4/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_5/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_5/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_5/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_7/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_7/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_7/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.001/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt-188130\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188130...\n",
      "INFO:tensorflow:Saving checkpoints for 188130 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188130...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62393 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 188130\n",
      "INFO:tensorflow:loss = 0.075049624, step = 188130\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188131...\n",
      "INFO:tensorflow:Saving checkpoints for 188131 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188131...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:48:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt-188131\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19965s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:48:53\n",
      "INFO:tensorflow:Saving dict for global step 188131: METRICS/E_LOSS = 0.2783377, METRICS/E_MAE = 0.36599022, METRICS/E_MSE = 0.2783377, METRICS/E_RMSE = 0.52757716, METRICS/TOT_LOSS = 0.27833784, global_step = 188131, loss = 0.27833784\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 188131: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt-188131\n",
      "INFO:tensorflow:Loss for final step: 0.075049624.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt-188131\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt-188131\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_0/model.ckpt-188131\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt-188551\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188551...\n",
      "INFO:tensorflow:Saving checkpoints for 188551 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188551...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62808 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 188551\n",
      "INFO:tensorflow:loss = 0.06538122, step = 188551\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188552...\n",
      "INFO:tensorflow:Saving checkpoints for 188552 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188552...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:48:59Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt-188552\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.20292s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:49:01\n",
      "INFO:tensorflow:Saving dict for global step 188552: METRICS/E_LOSS = 0.2564225, METRICS/E_MAE = 0.35548732, METRICS/E_MSE = 0.2564225, METRICS/E_RMSE = 0.50638175, METRICS/TOT_LOSS = 0.25642234, global_step = 188552, loss = 0.25642234\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 188552: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt-188552\n",
      "INFO:tensorflow:Loss for final step: 0.06538122.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt-188552\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt-188552\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_1/model.ckpt-188552\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt-187581\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187581...\n",
      "INFO:tensorflow:Saving checkpoints for 187581 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187581...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62134 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 187581\n",
      "INFO:tensorflow:loss = 0.07560482, step = 187581\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187582...\n",
      "INFO:tensorflow:Saving checkpoints for 187582 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187582...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:49:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt-187582\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.22014s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:49:10\n",
      "INFO:tensorflow:Saving dict for global step 187582: METRICS/E_LOSS = 0.2311185, METRICS/E_MAE = 0.33993563, METRICS/E_MSE = 0.2311185, METRICS/E_RMSE = 0.48074785, METRICS/TOT_LOSS = 0.23111841, global_step = 187582, loss = 0.23111841\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187582: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt-187582\n",
      "INFO:tensorflow:Loss for final step: 0.07560482.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt-187582\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt-187582\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_2/model.ckpt-187582\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt-187840\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187840...\n",
      "INFO:tensorflow:Saving checkpoints for 187840 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187840...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62226 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 187840\n",
      "INFO:tensorflow:loss = 0.08079471, step = 187840\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187841...\n",
      "INFO:tensorflow:Saving checkpoints for 187841 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187841...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:49:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt-187841\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.20021s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:49:18\n",
      "INFO:tensorflow:Saving dict for global step 187841: METRICS/E_LOSS = 0.30871257, METRICS/E_MAE = 0.3911349, METRICS/E_MSE = 0.30871257, METRICS/E_RMSE = 0.55561906, METRICS/TOT_LOSS = 0.3087124, global_step = 187841, loss = 0.3087124\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187841: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt-187841\n",
      "INFO:tensorflow:Loss for final step: 0.08079471.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt-187841\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt-187841\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_3/model.ckpt-187841\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt-188360\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188360...\n",
      "INFO:tensorflow:Saving checkpoints for 188360 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188360...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62544 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 188360\n",
      "INFO:tensorflow:loss = 0.0661963, step = 188360\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188361...\n",
      "INFO:tensorflow:Saving checkpoints for 188361 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188361...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:49:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt-188361\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.22699s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:49:27\n",
      "INFO:tensorflow:Saving dict for global step 188361: METRICS/E_LOSS = 0.22779182, METRICS/E_MAE = 0.34198853, METRICS/E_MSE = 0.22779182, METRICS/E_RMSE = 0.4772754, METRICS/TOT_LOSS = 0.22779197, global_step = 188361, loss = 0.22779197\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 188361: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt-188361\n",
      "INFO:tensorflow:Loss for final step: 0.0661963.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt-188361\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt-188361\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_4/model.ckpt-188361\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt-187829\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187829...\n",
      "INFO:tensorflow:Saving checkpoints for 187829 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187829...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62424 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 187829\n",
      "INFO:tensorflow:loss = 0.03503042, step = 187829\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187830...\n",
      "INFO:tensorflow:Saving checkpoints for 187830 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187830...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:49:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt-187830\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19423s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:49:35\n",
      "INFO:tensorflow:Saving dict for global step 187830: METRICS/E_LOSS = 0.26384664, METRICS/E_MAE = 0.35970017, METRICS/E_MSE = 0.26384664, METRICS/E_RMSE = 0.51366, METRICS/TOT_LOSS = 0.26384628, global_step = 187830, loss = 0.26384628\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187830: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt-187830\n",
      "INFO:tensorflow:Loss for final step: 0.03503042.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt-187830\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt-187830\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_5/model.ckpt-187830\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt-187578\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187578...\n",
      "INFO:tensorflow:Saving checkpoints for 187578 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187578...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62370 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 187578\n",
      "INFO:tensorflow:loss = 0.04780477, step = 187578\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187579...\n",
      "INFO:tensorflow:Saving checkpoints for 187579 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187579...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:49:41Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt-187579\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19806s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:49:43\n",
      "INFO:tensorflow:Saving dict for global step 187579: METRICS/E_LOSS = 0.22878347, METRICS/E_MAE = 0.3390382, METRICS/E_MSE = 0.22878347, METRICS/E_RMSE = 0.47831315, METRICS/TOT_LOSS = 0.22878341, global_step = 187579, loss = 0.22878341\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187579: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt-187579\n",
      "INFO:tensorflow:Loss for final step: 0.04780477.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt-187579\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt-187579\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_6/model.ckpt-187579\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt-188309\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188309...\n",
      "INFO:tensorflow:Saving checkpoints for 188309 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188309...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62336 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 188309\n",
      "INFO:tensorflow:loss = 0.042129155, step = 188309\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 188310...\n",
      "INFO:tensorflow:Saving checkpoints for 188310 into MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 188310...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:49:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt-188310\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19561s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:49:52\n",
      "INFO:tensorflow:Saving dict for global step 188310: METRICS/E_LOSS = 0.2646065, METRICS/E_MAE = 0.35873678, METRICS/E_MSE = 0.2646065, METRICS/E_RMSE = 0.5143992, METRICS/TOT_LOSS = 0.26460654, global_step = 188310, loss = 0.26460654\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 188310: MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt-188310\n",
      "INFO:tensorflow:Loss for final step: 0.042129155.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt-188310\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt-188310\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_7/model.ckpt-188310\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_8/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_0.0001/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_0/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_0/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_0/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_1/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt-187560\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187560...\n",
      "INFO:tensorflow:Saving checkpoints for 187560 into MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187560...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62225 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 187560\n",
      "INFO:tensorflow:loss = 0.32357544, step = 187560\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 187561...\n",
      "INFO:tensorflow:Saving checkpoints for 187561 into MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 187561...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:50:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt-187561\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.21440s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:50:16\n",
      "INFO:tensorflow:Saving dict for global step 187561: METRICS/E_LOSS = 0.31320223, METRICS/E_MAE = 0.412377, METRICS/E_MSE = 0.31320223, METRICS/E_RMSE = 0.55964476, METRICS/TOT_LOSS = 0.31320235, global_step = 187561, loss = 0.31320235\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 187561: MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt-187561\n",
      "INFO:tensorflow:Loss for final step: 0.32357544.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt-187561\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt-187561\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_2/model.ckpt-187561\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_3/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_3/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_3/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_4/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_4/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_4/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_5/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_5/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_5/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_6/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_7/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_7/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_7/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 91200\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt-125519\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 125519...\n",
      "INFO:tensorflow:Saving checkpoints for 125519 into MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 125519...\n",
      "INFO:tensorflow:No decrease in metric \"loss\" for 62571 steps, which is greater than or equal to max steps (1000) configured for early stopping.\n",
      "INFO:tensorflow:Requesting early stopping at global step 125519\n",
      "INFO:tensorflow:loss = 0.19990997, step = 125519\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 125520...\n",
      "INFO:tensorflow:Saving checkpoints for 125520 into MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 125520...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-25T08:50:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt-125520\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [40/400]\n",
      "INFO:tensorflow:Evaluation [80/400]\n",
      "INFO:tensorflow:Evaluation [120/400]\n",
      "INFO:tensorflow:Evaluation [160/400]\n",
      "INFO:tensorflow:Evaluation [200/400]\n",
      "INFO:tensorflow:Evaluation [240/400]\n",
      "INFO:tensorflow:Evaluation [280/400]\n",
      "INFO:tensorflow:Evaluation [320/400]\n",
      "INFO:tensorflow:Evaluation [360/400]\n",
      "INFO:tensorflow:Evaluation [400/400]\n",
      "INFO:tensorflow:Inference Time : 2.19649s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-25-08:50:45\n",
      "INFO:tensorflow:Saving dict for global step 125520: METRICS/E_LOSS = 0.42325708, METRICS/E_MAE = 0.43681446, METRICS/E_MSE = 0.42325708, METRICS/E_RMSE = 0.65058213, METRICS/TOT_LOSS = 0.42325702, global_step = 125520, loss = 0.42325702\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 125520: MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt-125520\n",
      "INFO:tensorflow:Loss for final step: 0.19990997.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt-125520\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt-125520\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_8/model.ckpt-125520\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from MD_max_weight_q_PhysProp/100_100_100/lr_1e-05/kfold_9/model.ckpt-200000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "lrs = [1e-2,1e-3, 1e-4, 1e-5]\n",
    "\n",
    "logps_martel = {}\n",
    "logps_star = {}\n",
    "logps_nonstar = {}\n",
    "\n",
    "for lr in lrs:\n",
    "\n",
    "    logps_martel['lr_{}'.format(lr)] = []\n",
    "    logps_star['lr_{}'.format(lr)] = []\n",
    "    logps_nonstar['lr_{}'.format(lr)] = []\n",
    "\n",
    "    for x in range(10):\n",
    "        # define the parameters\n",
    "        params = {\n",
    "        'model_dir':'MD_max_weight_q_PhysProp/100_100_100/lr_{}/kfold_{}'.format(lr,x),\n",
    "        'network':'bpnn',\n",
    "        'network_params':{\n",
    "        'nn_spec':{1:[100,100,100],6:[100,100,100],7:[100,100,100],8:[100,100,100]}},\n",
    "        'model_params': {'learning_rate': lr}\n",
    "        }\n",
    "        #split the dataset into train and test\n",
    "        ftrain = 'logp/DATASETS/PhysProps/MD_max/weight_q/sf_max_PhysProp_MD_weights_q_train_{}.csv'.format(x)\n",
    "        ftest  = 'logp/DATASETS/PhysProps/MD_max/weight_q/sf_max_PhysProp_MD_weights_q_test_{}.csv'.format(x)\n",
    "        dtrain = load_pd(ftrain)\n",
    "        dtest = load_pd(ftest)\n",
    "        dataset_train = lambda: load_feat_from_csv(dtrain,24,split={'train':10,'test':0})\n",
    "        dataset_test = lambda: load_feat_from_csv(dtest,24,split={'train':0,'test':10})\n",
    "        # yeild the train and test `input_fn`\n",
    "        train = lambda: dataset_train()['train'].repeat().shuffle(1000).apply(sparse_batch(100))\n",
    "        test = lambda: dataset_test()['test'].repeat().apply(sparse_batch(50))\n",
    "    \n",
    "        # initialize the model\n",
    "        model = potential_model(params)\n",
    "        # define the hooks\n",
    "        early_stopping = tf.estimator.experimental.stop_if_no_decrease_hook(model, metric_name='loss',\n",
    "                                                              max_steps_without_decrease=1000,\n",
    "                                                              min_steps=100)\n",
    "        # train and evaluate the model\n",
    "        train_spec = tf.estimator.TrainSpec(input_fn=train, hooks=[early_stopping] ,max_steps=200000)\n",
    "        eval_spec = tf.estimator.EvalSpec(input_fn=test, steps=400)\n",
    "        tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "    \n",
    "        # predict the data in martel \n",
    "        preds_martel = model.predict(input_fn=martel_train)\n",
    "        preds_star = model.predict(input_fn=star_train)\n",
    "        preds_nonstar = model.predict(input_fn=nonstar_train)\n",
    "    \n",
    "        logp_martel = []\n",
    "        for pred in preds_martel:\n",
    "            logp_martel.append(pred['logp'])\n",
    "        logps_martel['lr_{}'.format(lr)].append(logp_martel)\n",
    "    \n",
    "        logp_star = []\n",
    "        for pred in preds_star:\n",
    "            logp_star.append(pred['logp'])\n",
    "        logps_star['lr_{}'.format(lr)].append(logp_star)\n",
    "    \n",
    "        logp_nonstar = []\n",
    "        for pred in preds_nonstar:\n",
    "            logp_nonstar.append(pred['logp'])\n",
    "        logps_nonstar['lr_{}'.format(lr)].append(logp_nonstar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logps_martel_ave = {}\n",
    "logps_star_ave = {}\n",
    "logps_nonstar_ave = {}\n",
    "\n",
    "for lr in lrs:\n",
    "    # average the results\n",
    "    logps_martel_tmp = np.array(logps_martel['lr_{}'.format(lr)])\n",
    "    logps_martel_ave['lr_{}'.format(lr)] = np.mean(logps_martel_tmp,axis=0)\n",
    "    #logps_martel_ave\n",
    "\n",
    "    logps_star_tmp = np.array(logps_star['lr_{}'.format(lr)])\n",
    "    logps_star_ave['lr_{}'.format(lr)] = np.mean(logps_star_tmp,axis=0)\n",
    "\n",
    "    logps_nonstar_tmp = np.array(logps_nonstar['lr_{}'.format(lr)])\n",
    "    logps_nonstar_ave['lr_{}'.format(lr)] = np.mean(logps_nonstar_tmp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the true value of martel\n",
    "logp_exp_martel  = []\n",
    "for x in results_martel:\n",
    "    logp_exp_martel.append(x[3])\n",
    "\n",
    "# get the true value of star\n",
    "logp_exp_star = []\n",
    "for x in results_star:\n",
    "    logp_exp_star.append(x[3])\n",
    "    \n",
    "# get the true value of nonstar\n",
    "logp_exp_nonstar = []\n",
    "for x in results_nonstar:\n",
    "    logp_exp_nonstar.append(x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----0.01------#\n",
      "0.7305077543285456 0.8750989468172934 0.9354672344969082\n",
      "#-----0.001------#\n",
      "0.8662658163476108 1.2895026652684725 1.1355627086464546\n",
      "#-----0.0001------#\n",
      "0.9416855667213376 1.660318490925609 1.2885334651942917\n",
      "#-----1e-05------#\n",
      "0.8867232949004165 1.40568851631043 1.1856173566165562\n"
     ]
    }
   ],
   "source": [
    "# calculate the mae, mse, and rmse of martel\n",
    "for lr in lrs:\n",
    "    mae_martel = mean_absolute_error(logps_martel_ave['lr_{}'.format(lr)],logp_exp_martel)\n",
    "    mse_martel = mean_squared_error(logps_martel_ave['lr_{}'.format(lr)],logp_exp_martel)\n",
    "    print('#-----{}------#'.format(lr))\n",
    "    print(mae_martel,mse_martel,np.sqrt(mse_martel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----0.01------#\n",
      "1.0508350810957832 1.9036243225943548 1.3797189288381728\n",
      "#-----0.001------#\n",
      "0.6359736579303177 0.795303748035727 0.8917980421798015\n",
      "#-----0.0001------#\n",
      "0.5798313186566035 0.715589933685738 0.8459254894408479\n",
      "#-----1e-05------#\n",
      "0.5927400011200314 0.6319177019926682 0.7949325141121529\n"
     ]
    }
   ],
   "source": [
    "# calculate the mae, mse, and rmse of star\n",
    "for lr in lrs:\n",
    "    mae_star = mean_absolute_error(logps_star_ave['lr_{}'.format(lr)],logp_exp_star)\n",
    "    mse_star = mean_squared_error(logps_star_ave['lr_{}'.format(lr)],logp_exp_star)\n",
    "    print('#-----{}------#'.format(lr))\n",
    "    print(mae_star,mse_star,np.sqrt(mse_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----0.01------#\n",
      "0.5355292830071076 0.5601001035043623 0.7483983588332903\n",
      "#-----0.001------#\n",
      "0.2114724140194927 0.13947218621257135 0.37345975179739427\n",
      "#-----0.0001------#\n",
      "0.23172526935781576 0.1351622168748631 0.36764414435002646\n",
      "#-----1e-05------#\n",
      "0.34618648158731136 0.24742550890481388 0.49741884655169016\n"
     ]
    }
   ],
   "source": [
    "# calculate the mae, mse, and rmse of nonstar\n",
    "for lr in lrs:\n",
    "    mae_nonstar = mean_absolute_error(logps_nonstar_ave['lr_{}'.format(lr)],logp_exp_nonstar)\n",
    "    mse_nonstar = mean_squared_error(logps_nonstar_ave['lr_{}'.format(lr)],logp_exp_nonstar)\n",
    "    print('#-----{}------#'.format(lr))\n",
    "    print(mae_nonstar,mse_nonstar,np.sqrt(mse_nonstar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
