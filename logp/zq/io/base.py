#!/bin/python
# -*- coding: utf-8 -*-

import numpy as np
import math
import random
import tensorflow as tf


class _datalist(list):
	pass

def sparse_batch(batch_size, drop_remainder=False, num_parallel_calls=8):
	"""This returns a dataset operation that transforms single samples
	into sparse batched samples.
	
	Args:
		batch_size: see the parameters of the padded_batch
		drop_reminder (boolean): option for padded_batch
	"""

	def sparsify(tensors):
		atom_ind = tf.cast(tf.where(tensors['elems']), tf.int32)
		ind_1 = atom_ind[:, :1] # get the index of the molecule
		tensors['ind_1'] = ind_1
		elems = tf.gather_nd(tensors['elems'], atom_ind)
		coord = tf.gather_nd(tensors['coord'], atom_ind)
		fps = tf.gather_nd(tensors['fps'],atom_ind)
		tensors['elems'] = elems
		tensors['coord'] = coord
		tensors['fps'] = fps
		return tensors

	return lambda dataset: \
		dataset.padded_batch(batch_size, tf.compat.v1.data.get_output_shapes(dataset),
				drop_remainder=drop_remainder).map(
				sparsify, num_parallel_calls)

def flatten_nested(nested):
	"""return a list of the nested elements
	"""
	if isinstance(nested,dict):
		return sum([flatten_nested(v) for v in nested.values()],[])
	if isinstance(nested,list) and type(nested) != _datalist:
		return sum([flatten_nested(v) for v in nested],[])
	else:
		return [nested]

def map_nested(fn,nested):
	"""map fn to the nested structure
	"""
	if isinstance(nested,dict):
		return {k: map_nested(fn,v) for k,v in nested.items()}
	if isinstance(nested,list) and type(nested) != _datalist:
		return [map_nested(fn,v) for v in nested]
	else:
		return fn(nested)


def split_list(data_list, split={'train':8,'vali':1,'test':1},shuffle=True, seed=None):
	"""split the list according to a given ratio
	Args:
		to_split (list): a list to split
		split_ratio: a nested (list and dict) of split ratio
	
	Returns:
		A nest structure of splitted data list
	"""

	# convert a dict or list to type class
	dummy = _datalist(data_list)
	if shuffle:
		random.seed(seed)
		random.shuffle(dummy)
	
	data_tot = len(dummy)
	split_tot = float(sum(flatten_nested(split)))
	
	def get_split_num(x):
		return math.ceil(data_tot * x/split_tot)

	# here return a dict like:
	# {'train': num,'test':num}
	split_num = map_nested(get_split_num, split)
	
	def _pop_data(n):
		to_pop = dummy[:n]
		del dummy[:n]
		return _datalist(to_pop)

	# here return a dict like:
	# {'train': dataset generated by _pop_data,
	#   'test': dataset generated by _pop_data}
	splitted = map_nested(_pop_data, split_num)
	return splitted

def list_loader(feat_num=4):
	"""Decorator for building dataset loaders"""
	from functools import wraps
	format_dict = {
		'elems':{'dtype':tf.int32,'shape':[None]},
		'coord':{'dtype':tf.float32,'shape':[None,3]},
		'fps':{'dtype':tf.float32,'shape':[None,feat_num]},
		'logp':{'dtype':tf.float32,'shape':[]},
	}
		
	def decorator(func):
		@wraps(func)
		def data_loader(data_list, split={'train':8,'vali':1,'test':1},
						shuffle=True,seed=0):
			def _data_generator(data_list):
				for data in data_list:
					yield func(data)

			dtypes = {k:v['dtype'] for k,v in format_dict.items()}
			shapes = {k:v['shape'] for k,v in format_dict.items()}

			def generator_fn(data_list): return tf.data.Dataset.from_generator(
					lambda: _data_generator(data_list),dtypes,shapes)

			subsets = split_list(data_list,split,shuffle,seed)
			splitted = map_nested(generator_fn, subsets)

			return splitted
		return data_loader
	return decorator




if __name__ == '__main__':
	pass
